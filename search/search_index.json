{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"MeridianDB Overview","text":"<p>AI-first, Auto-RAG, a serverless database that enhances RAG with multi-dimensional retrieval. In addition to semantic search, we added temporal and behavioral awareness as well. NewSQL-inspired eventual consistency keeps all the vector database, content, features data synced across Cloudflare D1 and Vectorize. </p> <p>Leverages Cloudflare edge network with the great deal of innovation, the entire RAG pipeline runs near where your users are.</p>"},{"location":"#core-problem","title":"Core Problem","text":"<p>Traditional RAG suffers from:</p> <ul> <li>Catastrophic forgetting - AI retreival tend to forget important information. MeridianDB aims to improve tradtional RAG with multi-features on top of semantic to minimize or even elimante AI responses that forget important information.</li> <li>Lack of temporal awareness - All LLMs, tradtional vector, vector-graph databases lack tempooral sense in retreival, we designed and implemented intelligent algorithms and data-structure that target such problem.</li> <li>No behavioral learning - Some stored agent memories leads to terrible responses our system allow developers to integrate feedback loop between the users ( who uses your RAG pipeline ) and memories. Think like ChatGPT like/dislike button behind it very smart contnious learning that can be taken from passive to active phase with chainging agent configuration. </li> </ul>"},{"location":"#solution","title":"Solution","text":"<p>Multi-dimensional retrieval: - Semantic: Vector similarity search it's machine way of representing and understanding meaning behind text, video, images, audio ( note MeridianDB currently only support text ) - Temporal: Time-based memory decay - determine the temporal revlence of data as time go forward, how often the record is accessed by the agent, and who fast it decays. - Contextual: Task/environment context for the AI agent about the memory. - Behavioral: Success-based optimization when memories are used in generation, and user doesn't like it all data will get negative socring, we recommend setting the stability thrushhold to low value for a while, allowing your agent to collect enough behavioral metrices about your data, then you can set it to something that suits your usecase. </p>"},{"location":"#architecture","title":"Architecture","text":"<ul> <li> <p>(1), (2) Human clients: SDKs is for Agentic AI developers  Admin Portal for DB operators.</p> </li> <li> <p>(3) Worker API gateway: Handles requests from both clients and SDK integrations.</p> </li> <li> <p>(4) Eventual consistency model: Write operations are queued, simplifying retries and error handling. Follows Cloudflare\u2019s consistency model for Vectorize.</p> </li> <li> <p>(5), (6), (7), (8) Queues: Publish write events consumed by workers for vectorization and D1. Main goal is to keep retreival latency low and update features.</p> </li> <li> <p>(9) Retrieval engine: Performs multi-dimensional queries for the AI agent</p> </li> <li> <p>(10), (11), (12), (13), (14) Behavioral logging: Tracks Memory performance on tasks based on user feedback. Creates a feedback loop for continuous improvement. Configurable passive/active learning for each agent. </p> </li> </ul>"},{"location":"#mostly-tabular-data-for-features-no-graphs","title":"Mostly Tabular Data for Features no Graphs","text":"<p>In MeridianDB we aimed to maximize scalability and performance, therefore we designed to store extra features ( temporal and behavioral ) into SQL columns. </p> <p>We gurantee eventual consitency, we provide multiple settings that control the consistency experience to fit your business needs. </p> <p>The process is as follow :</p> <ol> <li>Agent send a retreival query.</li> <li>MeridianDB backend perform a similarity search on the query, with intentional over-fetching the results ( configurable ) with ( TOP-K) parameter.</li> <li>Content is fetched from D1.</li> <li>Data is filtered-out based on agent configuration, global configuration for all semantic, temporal, behavioral, contextual features.</li> <li>Temporal features job is enqueued for updating. Note we use event driven programming, the writes will be only published via queue, therefore, updating temporal features shouldn't have any impact on retreival speed. </li> </ol>"},{"location":"consistency/","title":"Consistency Model","text":""},{"location":"consistency/#eventual-consistency-design","title":"Eventual Consistency Design","text":"<p>Constraint: Vectorize operates under an eventually consistent model. Solution: Queue-based writes on retreival ( for temporal data as it depends on access frequency ) maintain consistency and minimize search latency by updating temporal features on access. We provide PMQ, a free and open-source queue implementation for Cloudflare Workers.</p> <p>Note: We do not have access to Cloudflare\u2019s low-level APIs, nor are we affiliated with them. However, this solution works well within the limits of Cloudflare\u2019s free plan.</p> <p>The design ensures that you can experiment with MeridianDB without barriers no need to pay for Cloudflare Workers to get started.</p> <p>Our Enterprise Edition uses Cloudflare Queues by default for maximum scalibilty.</p>"},{"location":"consistency/#write-pattern","title":"Write Pattern","text":"<pre><code>Store \u2192 Queue \u2192 [Process] \u2192 Vectorize + D1\n                    \u2193\n           [Retrieve] \u2190 Consistent State\n</code></pre>"},{"location":"consistency/#redundant-storage","title":"Redundant Storage","text":"<ul> <li>Vectorize: Embeddings + agentId metadata</li> <li>D1: Full multidimensional features with memory content</li> <li>KV: Counters, session state.</li> <li>We currently only support text.</li> </ul>"},{"location":"consistency/#queue-implementation","title":"Queue Implementation","text":""},{"location":"consistency/#temporal-features-queue","title":"Temporal Features Queue","text":"<ul> <li>Updates recency/frequency on access on memories we implemented our queue using cloudflare workers, with Write-ahead log and buffer-flush.</li> <li>Uses PMQ (Poor Man's Queue) for free tier.</li> <li>Configurable processing frequency.</li> </ul>"},{"location":"consistency/#behavioral-endpoint","title":"Behavioral Endpoint","text":"<ul> <li>Processes user feedback (success/failure).</li> <li>Updates success rate metrics on all involved memory based on user feedback.</li> <li>Independent of retrieval process simple webhook ( think like dislike generation on ChatGPT).</li> </ul>"},{"location":"consistency/#trade-offs","title":"Trade-offs","text":"<ul> <li>\u2705 Scalable, cost-effective</li> <li>\u2705 Automatic retries/failover  </li> <li>\u274c Reads may lag writes</li> <li>\u274c May Requires cleanup jobs ( the algorithm only filter out decayed, bad behavioral score data ).</li> </ul>"},{"location":"devdep/","title":"Deployment Guide","text":""},{"location":"devdep/#prerequisites","title":"Prerequisites","text":"<pre><code># Create Vectorize index\nnpx wrangler vectorize create meridiandb --dimensions=768 --metric=cosine\n\n# Create metadata index for agent separation\nnpx wrangler vectorize create-metadata-index meridiandb --property-name=agentId --type=string\n</code></pre>"},{"location":"devdep/#development","title":"Development","text":"<pre><code>npm install\nnpm run build -w shared\nnpm run server:migrations\nnpm run server:migrate:local\nnpm run dev\n</code></pre>"},{"location":"devdep/#initialization","title":"Initialization","text":"<ol> <li> <p>Set environment variables: <pre><code>{\n  \"ADMIN_EMAIL\": \"admin@admin.com\",\n  \"ADMIN_PASSWORD\": \"admin\", \n  \"SUPER_ADMIN_INIT_TOKEN\": \"your-secret-token\"\n}\n</code></pre></p> </li> <li> <p>Initialize super admin: <pre><code>curl -X POST /auth/init \\\n  -H \"Authorization: Bearer your-secret-token\"\n</code></pre></p> </li> </ol>"},{"location":"devdep/#production-deployment","title":"Production Deployment","text":"<pre><code># Deploy migrations\nnpx wrangler d1 execute meridiand1 --file=./drizzle/migrations/&lt;migration&gt;.sql\n\n# Deploy workers\nnpx wrangler deploy\n</code></pre>"},{"location":"devdep/#queue-configuration","title":"Queue Configuration","text":"<p>Temporal Queue (wrangler.jsonc): <pre><code>{\n  \"triggers\": {\n    \"crons\": [\"*/30 * * * *\"]  // Every 30 minutes\n  }\n}\n</code></pre></p> <p>Options: - <code>* * * * *</code> - Every 30s (high frequency) - <code>*/5 * * * *</code> - Every 5 minutes - <code>*/30 * * * *</code> - Every 30 minutes (default) - <code>0 * * * *</code> - Every hour</p>"},{"location":"limitations/","title":"Limitations &amp; Considerations","text":""},{"location":"limitations/#consistency","title":"Consistency","text":"<ul> <li>Eventual consistency: Reads may lag behind writes</li> <li>Vectorize constraint: Built on eventually consistent infrastructure</li> <li>Queue dependencies: Processing delays affect freshness</li> </ul>"},{"location":"limitations/#storage-limits","title":"Storage Limits","text":"<ul> <li>D1: 10GB database limit</li> <li>Vectorize: Dimension and metric constraints</li> <li>KV: 1GB per namespace</li> </ul>"},{"location":"limitations/#development-constraints","title":"Development Constraints","text":"<ul> <li>Cloudflare lock-in: Tight ecosystem coupling</li> <li>Context generation: Manual developer input required</li> <li>Learning curve: New retrieval model concepts</li> </ul>"},{"location":"limitations/#operational-considerations","title":"Operational Considerations","text":"<ul> <li>Temporal decay: Requires periodic cleanup jobs</li> <li>Queue management: PMQ vs Cloudflare Queues trade-offs</li> <li>Memory growth: Unbounded memory accumulation</li> </ul>"},{"location":"limitations/#performance-trade-offs","title":"Performance Trade-offs","text":"<ul> <li>SQL scoring: Scalable but limited complexity</li> <li>Over-fetching: Semantic search retrieves extra for filtering controlable through topK environment variable. </li> <li>Edge compute: Low latency but worker constraints</li> </ul>"},{"location":"retrieval/","title":"Multi-Dimensional Retrieval","text":""},{"location":"retrieval/#semantic-base-layer","title":"Semantic (Base Layer)","text":"<ul> <li>Vector similarity search</li> <li>Over-fetches initially for refinement</li> <li>Uses Vectorize with cosine similarity</li> </ul>"},{"location":"retrieval/#temporal-filtering","title":"Temporal Filtering","text":"<p>We use exponential decay with exponential boost algorithm and multiple parameters to tune the experience of temporal features based on <code>access count</code>, <code>lastAccessed Date</code> and <code>per agent configurations</code>.</p> <pre><code>// Exponential decay with frequency boost\nfunction calculateRecencyScore(accessCount, lastAccessed, config) {\n  const hoursSinceAccess = (now - lastAccessed) / (1000 * 60 * 60);\n  const timeDecay = Math.exp(-hoursSinceAccess / config.halfLifeHours);\n  const frequencyBoost = Math.log10(accessCount + 1);\n  return combinedScore; // 0-100 scale\n}\n</code></pre>"},{"location":"retrieval/#presets","title":"Presets","text":"<ul> <li>Balanced: 7-day half-life , suitable for balanced approach to decay.</li> <li>Aggressive: 3-day half-life  suitable for aggresive decay think ( chatbots, short-context window)</li> <li>Long-term: 30-day half-life long term decay, slow update of temporal feature ( think like codebases, AI assisted coding ).</li> </ul>"},{"location":"retrieval/#contextual-filtering","title":"Contextual Filtering","text":"<ul> <li>Developer-supplied context (task, environment)</li> <li>Included in response if semantic match</li> <li>No auto-generation (future feature)</li> </ul>"},{"location":"retrieval/#behavioral-filtering","title":"Behavioral Filtering","text":"<pre><code>// Wilson score confidence interval\nfunction wilsonScore(success, failure, confidence = 0.95) {\n  // Calculates confidence-based success rate\n  return score; // 0-1 scale\n}\n</code></pre> <p>Zero-sum mechanism: All memories in response share success/failure <pre><code>## 7. `configuration.md`\n```markdown\n# Configuration Guide\n\n## Agent Creation\n```javascript\nconst agentConfig = {\n  // Temporal features\n  halfLifeHours: 168,      // 7 days\n  timeWeight: 0.6,\n  frequencyWeight: 0.4,\n  decayCurve: 'hybrid',\n  decayFloor: 0.15,\n\n  // Behavioral features  \n  successRate: 0.0,        // Start at 0 for passive learning\n  stabilityThreshold: 0.0   // Start at 0 for passive learning\n};\n</code></pre></p>"},{"location":"retrieval/#preset-configurations","title":"Preset Configurations","text":""},{"location":"retrieval/#balanced-default","title":"Balanced (Default)","text":"<pre><code>{\n  halfLifeHours: 168,      // 7 days\n  timeWeight: 0.6,\n  frequencyWeight: 0.4,\n  decayCurve: 'hybrid',\n  decayFloor: 0.15\n}\n</code></pre>"},{"location":"retrieval/#aggressive-decay","title":"Aggressive Decay","text":"<pre><code>{\n  halfLifeHours: 72,       // 3 days  \n  timeWeight: 0.7,\n  frequencyWeight: 0.3,\n  decayCurve: 'exponential'\n}\n</code></pre>"},{"location":"retrieval/#long-term-memory","title":"Long-Term Memory","text":"<pre><code>{\n  halfLifeHours: 720,      // 30 days\n  timeWeight: 0.5, \n  frequencyWeight: 0.5,\n  decayCurve: 'polynomial'\n}\n</code></pre>"},{"location":"retrieval/#important-notes","title":"Important Notes","text":"<ul> <li>Choose carefully: Parameters affect memory filtering significantly</li> <li>Avoid changes: Don't modify after agent creation</li> <li>Eventual consistency: Config changes apply gradually</li> <li>Monitor: Use Admin UI to observe filtering effects</li> </ul>"},{"location":"retrieval/#behavioral-thresholds","title":"Behavioral Thresholds","text":"<ul> <li>Start with <code>successRate: 0.0</code> to avoid false positives</li> <li>Gradually increase as agent matures (e.g., 0.5, 0.7)</li> <li>Use Wilson score for confidence-based filtering</li> </ul>"},{"location":"sdk/","title":"SDK Usage","text":""},{"location":"sdk/#installation","title":"Installation","text":"<pre><code>npm install meridiandb-sdk\n</code></pre>"},{"location":"sdk/#basic-usage","title":"Basic Usage","text":"<pre><code>import { MeridianDBClient } from \"meridiandb-sdk\";\n\nconst client = new MeridianDBClient({\n  url: \"https://api.meridiandb.com\",\n  accessToken: \"your-token\"\n});\n\n// Store memory\nawait client.storeMemory({\n  agentId: \"chatbot-v1\",\n  content: \"User query and response\",\n  context: \"conversation context\",\n  // ... other features\n});\n\n// Retrieve memories  \nconst memories = await client.retrieveMemoriesSingleAgent({\n  query: \"user question\"\n});\n\n// Record feedback\nawait client.recordFeedback({\n  memories: [\"memory-id-1\", \"memory-id-2\"],\n  success: true\n});\n</code></pre>"},{"location":"sdk/#integration-pattern","title":"Integration Pattern","text":"<pre><code>class AIAgent {\n  async processMessage(userId, message) {\n    // 1. Retrieve relevant memories\n    const pastMemories = await this.client.retrieveMemoriesSingleAgent({\n      query: message\n    });\n\n    // 2. Generate response with context\n    const response = await this.generateResponse(message, pastMemories);\n\n    // 3. Store interaction\n    await this.storeInteraction(message, response);\n\n    return response;\n  }\n\n  async recordOutcome(memoryId, wasSuccessful) {\n    await this.client.recordFeedback({\n      memories: [memoryId],\n      success: wasSuccessful\n    });\n  }\n}\n</code></pre>"},{"location":"sdk/#learning-phases","title":"Learning Phases","text":""},{"location":"sdk/#passive-phase-initial","title":"Passive Phase (Initial)","text":"<ul> <li>Disable temporal/behavioral filtering</li> <li>Gather interaction data</li> <li>Set <code>stabilityThreshold = 0.0</code>, <code>successRate = 0.0</code> for your agent.</li> </ul>"},{"location":"sdk/#active-phase-mature","title":"Active Phase (Mature)","text":"<ul> <li>Enable filtering with tuned thresholds</li> <li>Filter low-success memories</li> <li>Apply temporal decay</li> <li>By carefully setting propre <code>stabilityThreshold</code>, <code>successRate = 0.0</code></li> </ul>"},{"location":"releases/v1.0.0/","title":"\ud83d\ude80 MeridianDB v1.0.0 \u2014 Release Notes","text":""},{"location":"releases/v1.0.0/#overview","title":"Overview","text":"<p>MeridianDB is now feature-complete and ready to ship. This release finalizes the architecture for an AI-first database that redefines retrieval for agents \u2014 going beyond semantic search with temporal, contextual, and behavioral dimensions.</p> <p>Our mission is to solve catastrophic forgetting in AI systems, helping agents strike the right balance between stability and plasticity.</p>"},{"location":"releases/v1.0.0/#whats-new-in-v100","title":"\u2728 What\u2019s New in v1.0.0","text":"<ul> <li> <p>Integrated Consistency Model</p> </li> <li> <p>Queue-based architecture ensures eventual consistency without developer orchestration.</p> </li> <li> <p>Redundant storage (Vector + D1) preserves multidimensional context and reliability.</p> </li> <li> <p>Multi-Dimensional Retrieval Engine</p> </li> <li> <p>Semantic: Over-fetched, refined retrieval beyond standard RAG pipelines.</p> </li> <li>Temporal: Data decays over time, supports factual/irrelevant tagging, and frequency weighting.</li> <li>Contextual: Filters results by task, environment, and developer-defined context.</li> <li> <p>Behavioral: Tracks retrieval impact on tasks for continuous feedback and improvement.</p> </li> <li> <p>Cloudflare-Native Architecture</p> </li> <li> <p>Global low-latency access.</p> </li> <li>Event-driven processing for scalable and cost-efficient operations.</li> <li> <p>Automatic retries, failover, and eventual consistency built-in.</p> </li> <li> <p>Operational Simplicity</p> </li> <li> <p>No need to glue multiple databases together \u2014 SDK + Operator UI included.</p> </li> <li>Simple developer API: <code>store</code>, <code>retrieve</code>, <code>log</code>.</li> </ul>"},{"location":"releases/v1.0.0/#architecture-highlights","title":"\ud83c\udfd7\ufe0f Architecture Highlights","text":"<ul> <li>Worker API gateway handles human and SDK requests.</li> <li>Eventual consistency via write queues and workers for vectorization.</li> <li>SQL-based feature scoring (no graph traversal) for performance and scalability.</li> <li>Built-in behavioral logging creates feedback loops for task success tracking.</li> </ul>"},{"location":"releases/v1.0.0/#benefits","title":"\ud83d\udee0\ufe0f Benefits","text":"<ol> <li>Integrated Consistency &amp; Reliability \u2013 No ghost embeddings, fewer race conditions.</li> <li>Simple Developer Experience \u2013 One API, no orchestration headaches.</li> <li>Native AI Feedback Loop \u2013 Behavioral insights for better retrieval over time.</li> <li>Cloudflare-Native Scalability \u2013 Low-latency global access by default.</li> </ol>"},{"location":"releases/v1.0.0/#known-limitations","title":"\u26a0\ufe0f Known Limitations","text":"<ul> <li>Eventual Consistency: Reads may lag slightly after writes.</li> <li>Feature Engineering: Developers must supply contextual features (future auto-context generation planned).</li> <li>Storage Cost: Temporal decay requires periodic cleanup jobs.</li> <li>Learning Curve: New retrieval model may require time to adopt.</li> <li>Cloudflare Coupling: Architecture is optimized for Cloudflare ecosystem.</li> </ul>"},{"location":"releases/v1.0.0/#launch-date","title":"\ud83d\uddd3\ufe0f Launch Date","text":"<p>Target shipping date: October 7, 2025.</p>"}]}